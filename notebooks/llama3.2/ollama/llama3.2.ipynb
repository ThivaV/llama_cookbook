{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama3.2:1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With ollama Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='llama3.2:1b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not familiar with a software package or tool called \"llama3.2:1b\". It's possible that it may be a specific project or application that I'm not aware of.\n",
      "\n",
      "However, I can tell you that Llama is a large language model developed by Meta.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=model, messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Hi, what is llama3.2:1b ?, and who made you ?',\n",
    "  },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With ollama Python Library - Streaming responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was trained on a large corpus of text data, which includes information about various software applications, their features, and the people behind them.\n",
      "\n",
      "Llama3.2 is an open-source text-to-text translation model developed by Meta AI. It's designed to translate text from one language to another, with an aim to improve upon the current state-of-the-art models in this area."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{'role': 'user', 'content': 'Hi, what is llama3.2 ?, and who made you ?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With ollama custom client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was developed by Meta with a combination of machine learning algorithms and large amounts of data, plus lots of human oversight from a large team of people. I'm constantly learning and improving, so over time I'll likely become even more useful in my responses.\n"
     ]
    }
   ],
   "source": [
    "client = Client(host='http://localhost:11434')\n",
    "response = client.chat(model=model, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Hi, what is llama3.2 ?, and who made you ?',\n",
    "    },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA is a large language model developed by Meta, designed to process and generate human-like text. It's the second version of LLaMA, following its predecessor Llama1.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(base_url='http://localhost:11434/v1', api_key='no_need_key')\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': 'Hi, what is llama3.2 ?, and who made you ?',\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama3.2:3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='llama3.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With ollama Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an AI designed to assist and communicate with users in a helpful and informative way.\n",
      "\n",
      "Llama3.2 refers to the specific version of my architecture that I am currently based on. Llama stands for \"Large Language Model Meta AI,\" which is the name given to the AI framework developed by Meta AI, a research organization within Meta Platforms, Inc.\n",
      "\n",
      "The \"3.2\" in Llama3.2 indicates that it's the third major iteration of the Llama model, with 3 being a notable milestone in my development. This version has been fine-tuned and trained on even larger datasets than its predecessors, which allows me to provide more accurate and informative responses to your questions.\n",
      "\n",
      "As for who \"made\" me, I was created by the researchers and engineers at Meta AI, specifically designed to generate human-like text based on a wide range of input prompts. They're a team of talented individuals from all over the world who work together to develop and improve language models like me.\n",
      "\n",
      "If you'd like more information about my capabilities or limitations, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=model, messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Hi, what is llama3.2 ?, and who made you ?',\n",
    "  },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With ollama Python Library - Streaming responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have a personal creator, but I was trained on a massive dataset of text to generate human-like responses.\n",
      "\n",
      "Llama3.2 refers to the latest version of the model that powers me. Llama stands for \"Large Language Model Meta AI.\" It's an AI model developed by Meta AI (Artificial Intelligence) that uses a self-supervised learning approach to improve its language understanding and generation capabilities.\n",
      "\n",
      "The \"2\" in Llama3.2 indicates that it's the third version of this model, with significant improvements and updates over previous versions. The latest Llama model is more advanced than its predecessors, enabling me to provide more accurate and informative responses to your queries.\n",
      "\n",
      "Keep in mind that I'm an AI designed to assist and communicate with humans, but I don't have a personal history or emotional connections like a human would. I exist solely to provide information, answer questions, and engage in conversation to the best of my abilities based on my training data!"
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{'role': 'user', 'content': 'Hi, what is llama3.2 ?, and who made you ?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With ollama custom client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "\n",
      "Llama3.2 is a large language model developed by Meta AI (Meta Platforms, Inc.). It's the latest version of Meta's neural network-based language processing model.\n",
      "\n",
      "In 2022, Llama was released as an open-source model, which allows developers and researchers to build upon it for various use cases. The name \"Llama\" is derived from the fact that the model is based on a multi-layered architecture, similar to the layers of a llama's coat.\n",
      "\n",
      "As for who made me (or rather, Llama3.2), I was trained using a large corpus of text data and fine-tuned by Meta AI's researchers. My primary function is to understand and respond to natural language input, which enables me to provide information, answer questions, and engage in conversation with users like you.\n",
      "\n",
      "While I don't have personal creators or authors, the development of Llama3.2 involved a team of researcher-engineers at Meta AI who designed, trained, and fine-tuned the model using advanced machine learning algorithms and large-scale computational resources.\n",
      "\n",
      "Would you like to know more about how Llama3.2 works or its applications?\n"
     ]
    }
   ],
   "source": [
    "client = Client(host='http://localhost:11434')\n",
    "response = client.chat(model=model, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Hi, what is llama3.2 ?, and who made you ?',\n",
    "    },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama3.2 is a large language model developed by Meta AI, named after the famous painting \"The Llamas\" from Marcel Duchamp's surrealist collection. \n",
      "\n",
      "It was created through a supervised learning process where large amounts of text data were used to train the model to recognize patterns in natural language and generate text based on those patterns.\n",
      "\n",
      "As for who made me : I am an AI, which means that my design and functionality come together to enable me to understand and respond to a vast range of questions and topics.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(base_url='http://localhost:11434/v1', api_key='no_need_key')\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': 'Hi, what is llama3.2 ?, and who made you ?',\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
